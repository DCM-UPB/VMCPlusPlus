\documentclass[11pt,a4paper,twoside]{article}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[english]{babel}
\usepackage{graphicx}
\usepackage{latexsym,amsmath,amssymb,amsthm}
\usepackage{makeidx}
\usepackage[usenames,dvipsnames]{color}
\usepackage[unicode=true,colorlinks=true,linkcolor=RoyalBlue,citecolor=RoyalBlue]{hyperref}
\usepackage{natbib}
\usepackage{lipsum}

% C++ formatting
\usepackage{listings}  % for code formatting
\usepackage{color}
\definecolor{listinggray}{gray}{0.9}
\definecolor{lbcolor}{rgb}{0.9,0.9,0.9}
\lstset{
  backgroundcolor=\color{lbcolor},
  tabsize=4,
  language=C++,
  captionpos=b,
  tabsize=3,
  frame=lines,
  numbers=left,
  numberstyle=\tiny,
  numbersep=5pt,
  breaklines=true,
  showstringspaces=false,
  basicstyle=\footnotesize,
  identifierstyle=\color{magenta},
  keywordstyle=\color[rgb]{0,0,1},
  commentstyle=\color{OliveGreen},
  stringstyle=\color{red}
}





\title{The VMC++ Library}
\author{Francesco Calcavecchia \and Jan Kessler}

\makeindex



\begin{document}
\maketitle

VMC++ (Variational Monte Carlo Plus Plus) is a C++ library which allows with few simple commands for the implementation of a Variational Monte Carlo calculation.
It provides the tools for describing a trial wave function and an Hamiltonian, and it uses this information to find the optimal values of the variational parameters embedded in the trial wave function, and therefore find the best approximation of the ground state.

The code has been developed using the standard C++11, and requires the MCI++ (https://github.com/francesco086/MCIntegratorPlusPlus) and NoisyFunMin (https://github.com/francesco086/NoisyFunMin) libraries.

In the following we will present the classes made available by the library.
At the beginning we will report the necessary \verb+#include+ call and the prototype of the class.
The comment \verb+TO DO+ indicates that the method needs to be implemented (as in the case of a pure virtual class).

First, we will present the virtual classes that should be instantiated for describing the trial wave function and the Hamiltonian.
Then, we will introduce the class that performs the whole Variational Monte Carlo calculation.


\section{WaveFunction} % (fold)
\label{sec:wave_function}

\begin{lstlisting}
// #import "WaveFunction.hpp"

/*
IMPLEMENTATIONS OF THIS INTERFACE MUST INCLUDE:

    - void setVP(const double *vp)
            set the variational parameters

    - void getVP(double *vp)
            get the variational parameters

    - void samplingFunction(const double * in, double * out)
            heritage from MCISamplingFunctionInterface, uses Psi^2

    - double getAcceptance()
            heritage from MCISamplingFunctionInterface

    - void computeAllDerivatives(const double *x)
            use the setters for derivatives values (setD1DivByWF, setD2DivByWF, etc.)

*/

class WaveFunction: public MCISamplingFunctionInterface, public MCICallBackOnAcceptanceInterface{
public:
    WaveFunction(const int &nspacedim, const int &npart, const int &ncomp, const int &nvp,
        bool flag_vd1=true, bool flag_d1vd1=true, bool flag_d2vd1=true);
    virtual ~WaveFunction();

    int getNSpaceDim();
    int getTotalNDim();
    int getNPart();
    int getNVP();


    // --- interface for manipulating the variational parameters
    virtual void setVP(const double *vp) = 0;    // --- MUST BE IMPLEMENTED
    virtual void getVP(double *vp) = 0;    // --- MUST BE IMPLEMENTED


    // --- computation of the derivatives
    // When called, this method computes all the internal values, such as the derivatives,
    // and stored them internally, ready to be accessed with the getters methods.
    // It requires the positions as input
    virtual void computeAllDerivatives(const double *x) = 0;    // --- MUST BE IMPLEMENTED


    // --- getters and setters for the derivatives
    // first derivative divided by the wf
    void setD1DivByWF(const int &id1, const double &d1_logwf);
    double getD1DivByWF(const int &id1);

    // second derivative divided by the wf
    void setD2DivByWF(const int &id2, const double &d2_logwf);
    double getD2DivByWF(const int &id2);

    // variational derivative divided by the wf
    bool hasVD1();
    void setVD1DivByWF(const int &ivd1, const double &vd1_logwf);
    double getVD1DivByWF(const int &ivd1);

    // cross derivative: first derivative and first variational derivative divided by the wf
    bool hasD1VD1();
    void setD1VD1DivByWF(const int &id1, const int &ivd1, const double &d1vd1_logwf);
    double getD1VD1DivByWF(const int &id1, const int &ivd1);

    // cross derivative: second derivative and first variational derivative divided by the wf
    bool hasD2VD1();
    void setD2VD1DivByWF(const int &id2, const int &ivd1, const double &d2vd1_logwf);
    double getD2VD1DivByWF(const int &id2, const int &ivd1);
\end{lstlisting}

The class \verb+WaveFunction+ is a pure virtual class introduced for representing the trial wave function.
The first thing that should be noticed, is that it is a child class of the MCI++ classes \verb+MCISamplingFunctionInterface+ and \verb+MCICallBackOnAcceptanceInterface+.
Please refer to the user manual of MCI++ to see the details of this class.
The user must be able to correctly implement the \verb+MCISamplingFunctionInterface+'s methods \verb+samplingFunction+ and \verb+getAcceptance+.

Let us now see in details the methods of the class \verb+WaveFunction+:
\begin{itemize}
\item \verb+WaveFunction+: The constructor. It is necessary to specify the number of dimensions of the space in which it is used (\verb+nspacedim+, typically $3$ dimensions), the number of particles that the wave function describes (\verb+npart+), the number of components of the wave function (\verb+ncomp+, which corresponds to \verb+nproto+ of the class \verb+MCISamplingFunctionInterface+), and the number of variational parameters used (\verb+nvp+). Moreover, with the optional parameters \verb+flag_vd1+, \verb+flag_d1vd1+, and \verb+flag_d2vd1+, one can specify if the variational derivatives $\frac{1}{\psi(x)} \frac{\partial \psi(x)}{\partial \alpha_{i}}$, $\frac{1}{\psi(x)} \frac{\partial^2 \psi(x)}{\partial x_i \partial \alpha_{i}}$, and $\frac{1}{\psi(x)} \frac{\partial^3 \psi(x)}{\partial x_i^2 \partial \alpha_{i}}$ are computed or not;
\item \verb+getNSpaceDim+: Returns \verb+nspacedim+;
\item \verb+getNPart+: Returns \verb+npart+;
\item \verb+getNVP+: Returns \verb+nvp+
\item \verb+setVP+: Set the variational parameters according to the provided \verb+nvp+-dimensional array \verb+vp+. Must be implemented by the user;
\item \verb+getVP+: Store in the \verb+nvp+-dimensional array \verb+vp+ the values of the variational parameters. Must be implemented by the user;
\item \verb+computeAllDerivatives+: This method must be implemented to compute all the derivatives that the wave function should implement. Once computed, all the derivatives, divided by the value of the wave function itself, should be stored internally using the methods \verb+setD1DivByWF+, \verb+setD2DivByWF+, \verb+setVD1DivByWF+, \verb+setD1VD1DivByWF+, \verb+setD2VD1DivByWF+;
\item \verb+hasVD1+, \verb+hasD1VD1+, \verb+hasD2VD1+: Tells whether the wave function implements the variational derivatives or not;
\item \verb+getD1DivByWF+, \verb+getD2DivByWF+, \verb+getVD1DivByWF+, \verb+getD1VD1DivByWF+, \verb+getD2VD1DivByWF+: In case the values were computed, returns the derivatives divided by the wave function value.
\end{itemize}





\subsection{Two-Body Jastrow}
\label{sub:two_body_jastrow}
There is a set of classes already prepared if you want to define a Two-Body Jastrow.

First of all you need to define the metric of your system, by implementing a child class of \verb+Metric+:
\begin{lstlisting}
class Metric{
public:
    Metric(const int &nspacedim);

    // --- Methods that must be implemented
    virtual double dist(const double * r1, const double * r2) = 0;
    virtual void distD1(const double * r1, const double * r2, double * out) = 0;
    virtual void distD2(const double * r1, const double * r2, double * out) = 0;
};
\end{lstlisting}
The method \verb+dist+ returns the distance between two particles.
The method \verb+distD1+ computes the first derivative of the distance function in respect to the coordinates of \verb+r1+ and \verb+r2+.
Therefore \verb+out+ must be \verb+2*_nspacedim+-dimensional.
The method \verb+distD2+ computes the second derivative.
In case you are interested in the Euclidean metric, you can use the \verb+EuclideanMetric+ class, which can be instanciated simply specifying the number of space dimensions. For example, for a $3$-dimensional space:
\begin{lstlisting}
EuclideanMetric * em = new EuclideanMetric(3);
\end{lstlisting}

Then you need to specify the Two-Body Pseudopotential by implementing a child class of \verb+TwoBodyPseudoPotential+:
\begin{lstlisting}
class TwoBodyPseudoPotential{
public:
    TwoBodyPseudoPotential(Metric * metric, const int &nvp, bool flag_vd1=true, bool flag_d1vd1=true, bool flag_d2vd1=true);
    virtual ~TwoBodyPseudoPotential();

    // --- Methods that must be implemented
    // manage variational parameters
    virtual void setVP(const double *vp) = 0;
    virtual void getVP(double *vp) = 0;
    // functions of the distance that define the pseudopotential
    virtual double ur(const double &r) = 0;
    virtual double urD1(const double &r) = 0;
    virtual double urD2(const double &r) = 0;
    virtual void urVD1(const double &r, double * vd1) = 0;
    virtual void urD1VD1(const double &r, double * d1vd1) = 0;
    virtual void urD2VD1(const double &r, double * d1vd1) = 0;
};
\end{lstlisting}
For example, the implementation of the Pseudopotential typically used for simulating $\text{He}$ atoms:
\begin{lstlisting}
class He3u2: public TwoBodyPseudoPotential{
private:
    double _b;
public:
    He3u2(EuclideanMetric * em):
    TwoBodyPseudoPotential(em, 1, true, true, true){
        _b = -1.;
    }

    void setVP(const double *vp){_b=vp[0];}
    void getVP(double *vp){vp[0]=_b;}

    double ur(const double &dist){
        return _b/pow(dist, 5);
    }
    double urD1(const double &dist){
        return -5.*_b/pow(dist, 6);
    }
    double urD2(const double &dist){
        return 30.*_b/pow(dist, 7);
    }
    void urVD1(const double &dist, double * vd1){
        vd1[0] = 1./pow(dist, 5);
    }
    void urD1VD1(const double &dist, double * d1vd1){
        d1vd1[0] = -5./pow(dist, 6);
    }
    void urD2VD1(const double &dist, double * d1vd1){
        d1vd1[0] = 30./pow(dist, 7);
    }
};
\end{lstlisting}

Finally, we are ready to declare a Two-Body Jastrow, simply by making use of the ready-to-use class \verb+TwoBodyJastrow+:
\begin{lstlisting}
EuclideanMetric * em = new EuclideanMetric(NSPACEDIM);
He3u2 * u2 = new He3u2(em);
TwoBodyJastrow * J = new TwoBodyJastrow(NPART, u2);
\end{lstlisting}


% subsection two_body_jastrow (end)


\subsection{MultiComponentWaveFunction}
\label{sub:multicomponentwavefunction}

The VMC++ library provides a class to handle in a simple way the wave function that is a product of multiple wave-function-like functions.
We report the prototype declaration, omitting as usual the part that are not useful for the final user.

\begin{lstlisting}
class MultiComponentWaveFunction: public WaveFunction{
private:
    std::vector<WaveFunction *> _wfs;

public:
    MultiComponentWaveFunction(const int &nspacedim, const int &npart, bool flag_vd1=true, bool flag_d1vd1=true, bool flag_d2vd1=true);

    void addWaveFunction(WaveFunction * wf);
};
\end{lstlisting}

Let's make a simple example: suppose we want to define a wave function that is product of two TwoBodyJastrow \verb+J1+ and \verb+J2+.
Of course the two wave functions should have the same number of dimensions and particles, and are also expected to have the same variational derivatives.
If one of this requirements are not met, an exception will be thrown when invoking the \verb+addWaveFunction()+ method.
Then we can proceed in the following way:

\begin{lstlisting}
MultiComponentWaveFunction * wf = MultiComponentWaveFunction(J1->getNSpaceDim(), J1->getNPart(), true, false, false);
wf->addWaveFunction(J1);
wf->addWaveFunction(J2);
\end{lstlisting}


% subsection multicomponentwavefunction (end)


% section wave_function (end)


\section{Hamiltonian} % (fold)
\label{sec:hamiltonian}

\begin{lstlisting}
// import "Hamiltonian.hpp"
class Hamiltonian: public MCIObservableFunctionInterface
{
   public:
      // Constructor and destructor
      Hamiltonian(const int &nspacedim, const int &npart, WaveFunction * wf):
         MCIObservableFunctionInterface(nspacedim*npart,4)
      virtual ~Hamiltonian(){}

      // Getters
      int getNSpaceDim();
      int getNPart();

      // Kinetic energy
      double localPBKineticEnergy(const double *in);
      double localJFKineticEnergy(const double *in);

      // Potential energy
      virtual double localPotentialEnergy(const double *in) = 0;  // TO DO

      // Heritage from MCIObservableFunctionInterface
      // already implemented
      void observableFunction(const double * in, double *out)
};
\end{lstlisting}

This pure virtual class is used to define the Hamiltonian of the system.
The user must take care of implementing only the \verb+localPotentialEnergy+ method, while all the rest is already provided.

\begin{itemize}
\item \verb+Hamiltonian+: The constructor. It requires the spacial number of dimensions (\verb+nspacedim+), the number of particles (\verb+npart+), and a pointer to an implementation of a \verb+WaveFunction+. Notice that the constructor inform the constructor of \verb+MCIObservableFunctionInterface+ that the Monte Carlo integral will be performed in a \verb+nspacedime+ $\times$ \verb+npart+ space, and that there will be $4$ observables, corresponding to the total, potential, kinetic, and Jackson-Feenberg kinetic energies, respectively. All the energies are computed as \emph{energy unit per particle};
\item \verb+getNSpaceDim+: Returns \verb+nspacedim+;
\item \verb+getNPart+: Returns \verb+getNPart+;
\item \verb+localPBKineticEnergy+: Returns the standard (Pandharipande-Bethe) local kinetic energy, in units of energy per particle. It requires the particle positions, provided through the array \verb+in+;
\item \verb+localJFKineticEnergy+: Returns the Jackson-Feenberg local kinetic energy;
\item \verb+localPotentialEnergy+: Returns the local potential energy. Must be implemented by the user;
\item \verb+observableFunction+: Returns the $4$ observables for the particle coordinates contained in the array \verb+in+. The observables will be contained in the array \verb+out+, and are the local total, potential, kinetic, and Jackson-Feenberg kinetic energies.
\end{itemize}

As example, we report the Hamiltonian for a one-dimensional, one-particle, harmonic oscillator:
\begin{equation}
  H = - \frac{\partial^2 \psi}{\partial x^2} + \frac{1}{2} \omega^2 x^2
\end{equation}

\begin{lstlisting}
class HarmonicOscialltor1D1P: public Hamiltonian
{
   protected:
      double _w;

   public:
      HarmonicOscialltor1D1P(const double w, WaveFunction * wf):
            Hamiltonian(1, 1, wf) {_w=w;}

      double localPotentialEnergy(const double *r)
      {
         return (0.5*_w*_w*(*r)*(*r));
      }
};
\end{lstlisting}

% section hamiltonian (end)



\section{VMC} % (fold)
\label{sec:vmc}

\begin{lstlisting}
// #include "VMC.hpp"
class VMC{

public:
   VMC(WaveFunction * wf, Hamiltonian * H);
   ~VMC();


   // Monte Carlo Integral within VMC should be performed using the MCI object provided by VMC
   MCI * getMCI(){return _mci;}


   // Computation of the variational energy
   void computeVariationalEnergy(const long & Nmc, double * E, double * dE);


   // Wave Function Optimization Methods
   void conjugateGradientOptimization(const long &E_Nmc, const long &grad_E_Nmc);

   void stochasticReconfigurationOptimization(const long &Nmc);

   void adamOptimization(const long &Nmc, const bool useSR = false);

   void simulatedAnnealingOptimization(const long &Nmc, const double &iota, const double &kappa, const double &lambda, gsl_siman_params_t &params);

   void nmsimplexOptimization(const long &Nmc);

};
\end{lstlisting}

The Variational Monte Carlo (VMC) method is a method that uses a minimisation method in order to find the variational parameters $\alpha$ of a trial wave function $\psi_{\alpha}$ such that the variational energy
\begin{equation}
  E(\psi_{\alpha}) = \frac{\int dR \, \psi_{\alpha}(R) H \psi_{\alpha}(R)}{\int dR \, \psi_{\alpha}(R) \psi_{\alpha}(R)}  \label{eq:variational_energy}
\end{equation}
is minimised.
In Eq. \eqref{eq:variational_energy} $H$ is the Hamiltonian, and we have assumed that both the Hamiltonian and the wave functions are real, as it is done by this library.
The minimisation can be achieved by using several optimisation algorithms. At the end of the optimization process, the wave function will be set to have the optimal variational parameters

\begin{itemize}
\item \verb+VMC+: The constructor. It requires a wave function, a Hamiltonian, and the number of sampling points to use for computing the energy (\verb+ENmc+) and the energy gradient (\verb+GNmc+) during the optimisation process. Notice that the constructor inform the constructor of \verb+NoisyFunctionWithGradient+ about the number of the number of variational parameters used by the wave function;
\item \verb+getMCI+: Returns a pointer to the \verb+MCI+ object used to compute the variational energy and the wave function derivatives;
\item \verb+computeVariationalEnergy+: Compute the total, kinetic, and potential energies for the given wave function. In fact \verb+E+ is expected to be an array of size 4, where \verb+E[0]+ is the total energy, \verb+E[1]+ is is the potential energy, \verb+E[2]+ is the Pandharipande-Bethe kinetic energy (i.e. the "real" kinetic energy), and \verb+E[3]+ is the Jackson-Feenberg kinetic energy;
\item \verb+conjugateGradientOptimization+: Optimise the trial wave function using the conjugate gradient method of the \href{https://github.com/francesco086/NoisyFunMin}{NoisyFunMin} library. It requires the number of sampling points for computing the energy during the linear search, and the number of samplings to use for computing the energy gradient;
\item \verb+stochasticReconfigurationOptimization+: Optimise the trial wave function using the Dynamic Descent method of the \href{https://github.com/francesco086/NoisyFunMin}{NoisyFunMin} library using as direction the one obtained using the Stochastic Reconfiguration (SR) approach. It requires the number of sampling points for computing the SR direction;
\item \verb+adamOptimization+: Optimise the trial wave function using the Adam optimization implementation of the  \href{https://github.com/francesco086/NoisyFunMin}{NoisyFunMin} library using as direction either the regular gradient or the one obtained using the Stochastic Reconfiguration (SR) approach.
\item \verb+simulatedAnnealingOptimization+: Optimise the trial wave function using the Simulated Annealing algorithm contained in the GSL library (read \href{https://www.gnu.org/software/gsl/doc/html/siman.html}{here}). The simulated annealing will try to minimise the target function
  $$
  \iota E + \kappa \sigma_E + \lambda \frac{\sqrt{ \sum_{i=1}^{N_{\alpha}} \alpha_i^2 }}{N_{\alpha}}
  $$
  where $E$ is the energy, $\sigma_E$ is the energy's standard deviation, and the last term represents a normalization factor, often used in Machine Learning. The weight of each term is controlled by the three parameters $\iota$ (\verb+iota+), $\kappa$ (\verb+kappa+), and $\lambda$ (\verb+lambda+), which must be provided to the method. Furthermore the method requires \verb+Nmc+, the number of sampling points for computing the target function integrals ($E$ and $\sigma_E$), and the GSL siman library parameters.
\item \verb+nmsimplexOptimization+: Optimise the trial wave function using the gradient-free Nelder-Mead-Simplex algorithm nmsimplex2, contained in the GSL library (see \href{https://www.gnu.org/software/gsl/doc/html/siman.html}{here}).
  
\end{itemize}

Examples can be found in the folder \verb+examples+.

% section vmc (end)

\section{MPI-VMC} % (fold)
\label{sec:mpivmc}

It is possible to use Message Passing Interface (MPI) for evaluating the MC integrals
in parallel. The library provides a namespace \verb+MPIVMC+ that contains a few
simple methods to use for creating a parallel VMC program. It contains two
versions of code, one for regular single thread execution and one actual MPI
version, which are switched by the \verb+USE_MPI+ pre-processor flag. This way
you can compile the library without having MPI installed and you can use the same
executable code for MPI and non-MPI library version.
\\\\The use of MPI code can conveniently be enabled by setting \verb+USE_MPI+ to $1$ in your
config.sh before compiling. In that case an MPI implementation is expected to be
found on your system. Afterwards, do the following in your executable code:

\begin{lstlisting}
#include "MPIVMC.hpp"
// start of main
const int myrank = MPIVMC::Init();
// ...
MPIVMC::Integrate(mci, Nmc, average, error);
// ...
if (myrank==0) { /* printout etc. */ }
// ...
MPIVMC::Finalize();
// end of main
\end{lstlisting}
Remember not to encapsulate any code within \verb+if (myrank==0){}+ clauses,
that is actually relevant to all threads. Typically this means only file and
console output belongs there.
\\\\Finally, compile the executable with a MPI compiler wrapper and execute it with
\verb+mpirun+ or similar software on your system.

% section mpivmc (end)

\printindex

\end{document}
